# OpenTelWatcher NDJSON File Interpretation Guide

This guide explains how to interpret the NDJSON (Newline Delimited JSON) telemetry files generated by OpenTelWatcher. It is intended for Claude skills, agents, and developers analyzing application telemetry data.

## Table of Contents

1. [File Format Overview](#file-format-overview)
2. [File Naming Patterns](#file-naming-patterns)
3. [Understanding NDJSON Structure](#understanding-ndjson-structure)
4. [.NET OpenTelemetry Terminology](#net-opentelemetry-terminology)
5. [OpenTelemetry Data Types](#opentelemetry-data-types)
   - [Traces](#traces)
   - [Logs](#logs)
   - [Metrics](#metrics)
6. [Error Files](#error-files)
7. [Working with Timestamps](#working-with-timestamps)
8. [Testing Workflow Guidelines](#testing-workflow-guidelines)
9. [Common Analysis Patterns](#common-analysis-patterns)

---

## File Format Overview

OpenTelWatcher receives OpenTelemetry Protocol (OTLP) data in binary Protobuf format via HTTP endpoints and persists it to disk as NDJSON files. Each line in an NDJSON file is a complete, valid JSON object representing a single telemetry export request.

**Key Characteristics:**
- **Format**: NDJSON (Newline Delimited JSON) - one JSON object per line
- **Encoding**: UTF-8 text files
- **Source Protocol**: OTLP/HTTP with Protobuf payloads converted to JSON
- **JSON Standard**: Proto3 JSON Mapping with specific OTLP deviations (see below)

**OTLP JSON Encoding Deviations from Standard Protobuf:**
1. **Trace/Span IDs**: Encoded as **case-insensitive hex strings** (not base64)
   - Example: `"traceId": "5B8EFFF798038103D269B633813FC60C"`
2. **Enum Values**: Always encoded as **integer values** (not string names)
   - Example: `"kind": 2` for SPAN_KIND_SERVER (not `"kind": "SPAN_KIND_SERVER"`)
3. **Field Names**: Use **camelCase** (not snake_case)
   - Example: `"droppedAttributesCount"` (not `"dropped_attributes_count"`)
4. **64-bit Integers**: Encoded as **decimal strings** in JSON
   - Example: `"timeUnixNano": "1699889318780000000"`

---

## File Naming Patterns

### Normal Telemetry Files

Files follow the pattern: `{signal}.{timestamp}.ndjson`

**Components:**
- `{signal}`: Type of telemetry data - `traces`, `logs`, or `metrics`
- `{timestamp}`: Creation timestamp in format `YYYYMMDD_HHMMSS_mmm` (24-hour format with milliseconds)
- Extension: Always `.ndjson`

**Examples:**
```
traces.20251116_143022_456.ndjson
logs.20251116_143022_456.ndjson
metrics.20251116_143100_789.ndjson
```

### Error Files

Error files contain only telemetry data with detected errors/exceptions. They mirror normal files with an additional `.errors` suffix: `{signal}.{timestamp}.errors.ndjson`

**Examples:**
```
traces.20251116_143022_456.errors.ndjson
logs.20251116_143022_456.errors.ndjson
```

**Error Detection Criteria:**

**Traces** (checked before writing):
- Span status code = `STATUS_CODE_ERROR` (enum value `2`)
- Span contains events with name = `"exception"`

**Logs** (checked before writing):
- Severity number >= 17 (ERROR: 17-20, FATAL: 21-24)
- Attributes contain exception keys: `exception.type`, `exception.message`, or `exception.stacktrace`

**Metrics**: No error detection (metrics don't have error semantics)

### File Rotation

Files automatically rotate when they reach the configured maximum size (default: configurable via `--max-file-size-mb` option). A new file with a fresh timestamp is created, ensuring chronological organization.

---

## Understanding NDJSON Structure

Each line is a self-contained JSON object. To parse:

1. **Read line-by-line** (do not parse entire file as single JSON array)
2. **Parse each line** as individual JSON object
3. **Process sequentially** - lines are appended in chronological order

**Example Python parsing:**
```python
import json

with open('traces.20251116_143022_456.ndjson', 'r') as f:
    for line in f:
        data = json.loads(line)
        # Process each export request
        process_trace_export(data)
```

**Example Node.js parsing:**
```javascript
const fs = require('fs');
const readline = require('readline');

const rl = readline.createInterface({
  input: fs.createReadStream('traces.20251116_143022_456.ndjson')
});

rl.on('line', (line) => {
  const data = JSON.parse(line);
  // Process each export request
  processTraceExport(data);
});
```

**Example .NET 10 parsing (using `dotnet run`):**

Create a file `parse_traces.cs`:
```csharp
#!/usr/bin/dotnet run
#:package System.Text.Json

using System.Text.Json;

// Read and parse NDJSON file line by line
foreach (var line in File.ReadLines("traces.20251116_143022_456.ndjson"))
{
    using var doc = JsonDocument.Parse(line);
    var root = doc.RootElement;

    // Process each export request
    ProcessTraceExport(root);
}

void ProcessTraceExport(JsonElement data)
{
    if (data.TryGetProperty("resourceSpans", out var resourceSpans))
    {
        foreach (var rs in resourceSpans.EnumerateArray())
        {
            // Process resource spans
            Console.WriteLine($"Processing resource span...");
        }
    }
}
```

Run directly:
```bash
dotnet run parse_traces.cs
# Or make executable on Unix-like systems
chmod +x parse_traces.cs
./parse_traces.cs
```

---

## .NET OpenTelemetry Terminology

**.NET uses different terminology** for OpenTelemetry concepts compared to other languages. When analyzing NDJSON files from .NET applications, be aware of these mappings:

### Terminology Mapping

| OpenTelemetry Standard | .NET Class/API | Description |
|------------------------|----------------|-------------|
| **Span** | `Activity` | Represents a single operation/unit of work |
| **Tracer** | `ActivitySource` | Creates and manages Activities (Spans) |
| **Trace** | `Activity` with same `TraceId` | Distributed trace (collection of related Activities) |
| **Trace ID** | `Activity.TraceId` | Unique identifier for entire trace |
| **Span ID** | `Activity.SpanId` | Unique identifier for individual Activity |
| **Parent Span ID** | `Activity.ParentSpanId` | Parent Activity's SpanId |

### Why the Difference?

.NET introduced the `Activity` and `ActivitySource` APIs **before** OpenTelemetry was standardized. These APIs are now the official .NET implementation of OpenTelemetry tracing, but the naming convention was preserved for backward compatibility.

### Code Example: .NET Activity → NDJSON Span

When you create an Activity in .NET code:

```csharp
using var activity = activitySource.StartActivity("GET /api/users");
activity?.SetTag("http.method", "GET");
activity?.SetStatus(ActivityStatusCode.Ok);
```

It appears in the NDJSON file as a **Span**:

```json
{
  "resourceSpans": [{
    "scopeSpans": [{
      "spans": [{
        "name": "GET /api/users",
        "kind": 2,
        "attributes": [
          {"key": "http.method", "value": {"stringValue": "GET"}}
        ],
        "status": {"code": 1}
      }]
    }]
  }]
}
```

### Practical Implications

When analyzing .NET application traces:
- **Search for "Activity"** in .NET source code to find where spans are created
- **ActivitySource.Name** corresponds to instrumentation scope name in NDJSON
- **Activity.Status** maps to span `status.code` (Ok=1, Error=2, Unset=0)
- **Activity.Events** become span `events[]` array
- **Activity.Tags** become span `attributes[]` array

### Example: Mapping .NET Code to NDJSON

**.NET Application Code:**
```csharp
using System.Diagnostics;

var source = new ActivitySource("MyApp.Orders");

using var activity = source.StartActivity("ProcessOrder", ActivityKind.Server);
activity?.SetTag("order.id", "12345");
activity?.AddEvent(new ActivityEvent("Order validated"));

try
{
    // Process order...
}
catch (Exception ex)
{
    activity?.SetStatus(ActivityStatusCode.Error, ex.Message);
    activity?.RecordException(ex);
}
```

**Resulting NDJSON (in traces.*.ndjson):**
```json
{
  "resourceSpans": [{
    "scopeSpans": [{
      "scope": {
        "name": "MyApp.Orders"
      },
      "spans": [{
        "name": "ProcessOrder",
        "kind": 2,
        "attributes": [
          {"key": "order.id", "value": {"stringValue": "12345"}}
        ],
        "events": [
          {"name": "Order validated", "timeUnixNano": "..."}
        ],
        "status": {
          "code": 2,
          "message": "Exception message here"
        }
      }]
    }]
  }]
}
```

**Key Takeaway:** When you see `Activity` in .NET code, you're looking at what will become a **Span** in the NDJSON file. When you see `ActivitySource`, you're looking at what will become the **Scope** (instrumentation library).

---

## OpenTelemetry Data Types

### Traces

Traces represent distributed request flows through your application. Each NDJSON line contains an `ExportTraceServiceRequest` object.

#### Top-Level Structure

```json
{
  "resourceSpans": [
    {
      "resource": { /* Resource attributes */ },
      "scopeSpans": [
        {
          "scope": { /* Instrumentation scope */ },
          "spans": [ /* Array of spans */ ]
        }
      ],
      "schemaUrl": "https://opentelemetry.io/schemas/1.21.0"
    }
  ]
}
```

#### Hierarchical Organization

```
ExportTraceServiceRequest
└── resourceSpans[] (grouped by resource/service)
    ├── resource (describes the service/process)
    │   └── attributes[] (e.g., service.name, host.name)
    └── scopeSpans[] (grouped by instrumentation library)
        ├── scope (library that created the spans)
        │   ├── name (e.g., "MyApp.Instrumentation")
        │   └── version
        └── spans[] (individual operations)
```

#### Resource Attributes (Common)

Resources describe the entity producing telemetry (service, host, container):

```json
{
  "resource": {
    "attributes": [
      {"key": "service.name", "value": {"stringValue": "my-api"}},
      {"key": "service.version", "value": {"stringValue": "1.2.3"}},
      {"key": "service.instance.id", "value": {"stringValue": "abc-123"}},
      {"key": "host.name", "value": {"stringValue": "server-01"}},
      {"key": "deployment.environment", "value": {"stringValue": "production"}}
    ]
  }
}
```

#### Span Structure

Each span represents a single operation:

```json
{
  "traceId": "5b8efff798038103d269b633813fc60c",
  "spanId": "051581bf3cb55c13",
  "parentSpanId": "5fb15e5e71b90c45",
  "name": "GET /api/users",
  "kind": 2,
  "startTimeUnixNano": "1699889318780000000",
  "endTimeUnixNano": "1699889318950000000",
  "attributes": [
    {"key": "http.method", "value": {"stringValue": "GET"}},
    {"key": "http.url", "value": {"stringValue": "/api/users"}},
    {"key": "http.status_code", "value": {"intValue": "200"}}
  ],
  "status": {
    "code": 0,
    "message": ""
  },
  "events": [],
  "links": []
}
```

**Key Span Fields:**

| Field | Type | Description |
|-------|------|-------------|
| `traceId` | string (hex) | Unique trace identifier shared by all spans in the trace |
| `spanId` | string (hex) | Unique span identifier |
| `parentSpanId` | string (hex) | Parent span ID (empty for root spans) |
| `name` | string | Operation name (e.g., "GET /api/users", "query database") |
| `kind` | integer | Span kind: 0=UNSPECIFIED, 1=INTERNAL, 2=SERVER, 3=CLIENT, 4=PRODUCER, 5=CONSUMER |
| `startTimeUnixNano` | string | Start timestamp in nanoseconds since Unix epoch |
| `endTimeUnixNano` | string | End timestamp in nanoseconds since Unix epoch |
| `attributes` | array | Key-value metadata (see Semantic Conventions) |
| `status` | object | Outcome: code (0=UNSET, 1=OK, 2=ERROR), message |
| `events` | array | Timestamped events during span (e.g., exceptions, logs) |
| `links` | array | Links to other spans (e.g., cross-trace references) |

**Span Kinds (Enum Values):**
- `0` - `SPAN_KIND_UNSPECIFIED`: Default/unknown
- `1` - `SPAN_KIND_INTERNAL`: Operation within a single process
- `2` - `SPAN_KIND_SERVER`: Synchronous request handler (server-side)
- `3` - `SPAN_KIND_CLIENT`: Synchronous outbound request (client-side)
- `4` - `SPAN_KIND_PRODUCER`: Asynchronous message sent
- `5` - `SPAN_KIND_CONSUMER`: Asynchronous message received

**Span Status Codes:**
- `0` - `STATUS_CODE_UNSET`: Default (success implied)
- `1` - `STATUS_CODE_OK`: Explicitly successful
- `2` - `STATUS_CODE_ERROR`: Operation failed (triggers error file)

#### Span Events

Events represent point-in-time occurrences during a span:

```json
{
  "events": [
    {
      "timeUnixNano": "1699889318850000000",
      "name": "exception",
      "attributes": [
        {"key": "exception.type", "value": {"stringValue": "System.InvalidOperationException"}},
        {"key": "exception.message", "value": {"stringValue": "User not found"}},
        {"key": "exception.stacktrace", "value": {"stringValue": "at MyApp.UserService..."}}
      ]
    }
  ]
}
```

**Common Event Names:**
- `exception`: Exception/error occurred (triggers error file)
- `log`: Log message within span
- Custom application events

#### Trace Hierarchy Example

A typical HTTP request trace hierarchy:

```
Root Span (traceId: abc123)
├── Span 1: "GET /api/orders" (kind: SERVER, parentSpanId: "")
    ├── Span 2: "SELECT orders" (kind: CLIENT, parentSpanId: span1_id)
    └── Span 3: "POST /payment" (kind: CLIENT, parentSpanId: span1_id)
        └── Span 4: "Process payment" (kind: INTERNAL, parentSpanId: span3_id)
```

**Analysis Tips:**
- All spans with same `traceId` belong to one distributed trace
- Root spans have empty/missing `parentSpanId`
- Calculate duration: `(endTimeUnixNano - startTimeUnixNano) / 1e9` seconds
- Follow parent-child relationships via `parentSpanId` → `spanId` links

---

### Logs

Log records represent structured application logs. Each NDJSON line contains an `ExportLogsServiceRequest` object.

#### Top-Level Structure

```json
{
  "resourceLogs": [
    {
      "resource": { /* Resource attributes */ },
      "scopeLogs": [
        {
          "scope": { /* Instrumentation scope */ },
          "logRecords": [ /* Array of log records */ ]
        }
      ],
      "schemaUrl": "https://opentelemetry.io/schemas/1.21.0"
    }
  ]
}
```

#### Hierarchical Organization

```
ExportLogsServiceRequest
└── resourceLogs[] (grouped by resource/service)
    ├── resource (describes the service/process)
    │   └── attributes[] (e.g., service.name)
    └── scopeLogs[] (grouped by instrumentation library)
        ├── scope (logger/library)
        └── logRecords[] (individual log entries)
```

#### LogRecord Structure

```json
{
  "timeUnixNano": "1699889318780000000",
  "observedTimeUnixNano": "1699889318781000000",
  "severityNumber": 13,
  "severityText": "INFO",
  "body": {
    "stringValue": "User logged in successfully"
  },
  "attributes": [
    {"key": "user.id", "value": {"stringValue": "12345"}},
    {"key": "http.method", "value": {"stringValue": "POST"}},
    {"key": "http.url", "value": {"stringValue": "/auth/login"}}
  ],
  "traceId": "5b8efff798038103d269b633813fc60c",
  "spanId": "051581bf3cb55c13",
  "flags": 1
}
```

**Key LogRecord Fields:**

| Field | Type | Description |
|-------|------|-------------|
| `timeUnixNano` | string | Timestamp when event occurred (nanoseconds since Unix epoch) |
| `observedTimeUnixNano` | string | Timestamp when log was observed/collected |
| `severityNumber` | integer | Numeric severity level (see table below) |
| `severityText` | string | Human-readable severity (e.g., "INFO", "ERROR") |
| `body` | object | Log message (stringValue, intValue, boolValue, or structured data) |
| `attributes` | array | Contextual key-value metadata |
| `traceId` | string (hex) | Associated trace ID (for correlation with traces) |
| `spanId` | string (hex) | Associated span ID (for correlation with traces) |
| `flags` | integer | Trace flags (bit 0 = sampled) |

#### Severity Levels

| severityNumber | severityText | Description |
|----------------|--------------|-------------|
| 1-4 | TRACE | Finest-grained debugging |
| 5-8 | DEBUG | Detailed debugging information |
| 9-12 | INFO | Informational messages |
| 13-16 | WARN | Warning messages |
| **17-20** | **ERROR** | **Error conditions (triggers error file)** |
| **21-24** | **FATAL** | **Critical failures (triggers error file)** |

#### Log Body Types

The `body` field can contain different value types:

```json
// String body (most common)
{"body": {"stringValue": "User authentication failed"}}

// Structured body (map)
{"body": {"kvlistValue": {"values": [
  {"key": "event", "value": {"stringValue": "purchase"}},
  {"key": "amount", "value": {"doubleValue": 49.99}},
  {"key": "currency", "value": {"stringValue": "USD"}}
]}}}

// Array body
{"body": {"arrayValue": {"values": [
  {"intValue": "1"},
  {"intValue": "2"},
  {"intValue": "3"}
]}}}
```

#### Exception Logs (Error File Triggers)

Logs with exception information automatically go to error files:

```json
{
  "severityNumber": 17,
  "severityText": "ERROR",
  "body": {"stringValue": "Database connection failed"},
  "attributes": [
    {"key": "exception.type", "value": {"stringValue": "System.Data.SqlClient.SqlException"}},
    {"key": "exception.message", "value": {"stringValue": "Cannot connect to server"}},
    {"key": "exception.stacktrace", "value": {"stringValue": "at System.Data..."}}
  ]
}
```

**Exception Attribute Keys (OpenTelemetry Standard):**
- `exception.type`: Fully-qualified exception class name
- `exception.message`: Exception message
- `exception.stacktrace`: Full stack trace string

---

### Metrics

Metrics represent numerical measurements over time. Each NDJSON line contains an `ExportMetricsServiceRequest` object.

#### Top-Level Structure

```json
{
  "resourceMetrics": [
    {
      "resource": { /* Resource attributes */ },
      "scopeMetrics": [
        {
          "scope": { /* Instrumentation scope */ },
          "metrics": [ /* Array of metrics */ ]
        }
      ],
      "schemaUrl": "https://opentelemetry.io/schemas/1.21.0"
    }
  ]
}
```

#### Hierarchical Organization

```
ExportMetricsServiceRequest
└── resourceMetrics[] (grouped by resource/service)
    ├── resource (describes the service/process)
    │   └── attributes[] (e.g., service.name)
    └── scopeMetrics[] (grouped by instrumentation library)
        ├── scope (meter/library)
        └── metrics[] (individual metric series)
```

#### Metric Types

OpenTelemetry supports multiple metric data types, each with specific semantics:

##### 1. Gauge

Represents a sampled value at a point in time (non-cumulative).

**Use Cases:** CPU usage, memory usage, queue depth, temperature

```json
{
  "name": "system.memory.usage",
  "description": "Current memory usage in bytes",
  "unit": "By",
  "gauge": {
    "dataPoints": [
      {
        "attributes": [
          {"key": "state", "value": {"stringValue": "used"}}
        ],
        "timeUnixNano": "1699889318780000000",
        "asDouble": 4294967296.0
      }
    ]
  }
}
```

##### 2. Sum (Counter)

Represents cumulative values that increase over time.

**Use Cases:** Request counts, bytes transferred, errors total

**Types:**
- **Monotonic**: Only increases (never decreases) - typical counters
- **Non-Monotonic**: Can increase or decrease

```json
{
  "name": "http.server.requests",
  "description": "Total HTTP requests received",
  "unit": "1",
  "sum": {
    "dataPoints": [
      {
        "attributes": [
          {"key": "http.method", "value": {"stringValue": "GET"}},
          {"key": "http.status_code", "value": {"intValue": "200"}}
        ],
        "startTimeUnixNano": "1699889000000000000",
        "timeUnixNano": "1699889318780000000",
        "asInt": "1547"
      }
    ],
    "aggregationTemporality": 2,
    "isMonotonic": true
  }
}
```

**Aggregation Temporality:**
- `1` - `AGGREGATION_TEMPORALITY_DELTA`: Value since last export
- `2` - `AGGREGATION_TEMPORALITY_CUMULATIVE`: Total since start

##### 3. Histogram

Represents distribution of values in buckets.

**Use Cases:** Request duration, response size, latency percentiles

```json
{
  "name": "http.server.duration",
  "description": "HTTP request duration",
  "unit": "ms",
  "histogram": {
    "dataPoints": [
      {
        "attributes": [
          {"key": "http.method", "value": {"stringValue": "GET"}}
        ],
        "startTimeUnixNano": "1699889000000000000",
        "timeUnixNano": "1699889318780000000",
        "count": "152",
        "sum": 5432.0,
        "bucketCounts": ["5", "48", "78", "18", "3"],
        "explicitBounds": [10.0, 50.0, 100.0, 500.0, 1000.0],
        "min": 2.3,
        "max": 987.5
      }
    ],
    "aggregationTemporality": 2
  }
}
```

**Histogram Fields:**
- `count`: Total number of measurements
- `sum`: Sum of all measurements
- `bucketCounts`: Number of values in each bucket
- `explicitBounds`: Upper bounds of buckets (n bounds = n+1 buckets)
- `min`/`max`: Minimum and maximum values (optional)

**Bucket Interpretation:**
- Bucket 0: (-∞, bounds[0]]
- Bucket i: (bounds[i-1], bounds[i]]
- Bucket n: (bounds[n-1], +∞)

Example with bounds `[10, 50, 100]` and counts `[5, 48, 78, 18]`:
- 5 values ≤ 10ms
- 48 values in (10, 50] ms
- 78 values in (50, 100] ms
- 18 values > 100ms

##### 4. Summary (Less Common)

Pre-computed percentiles from client side.

```json
{
  "name": "response.time",
  "summary": {
    "dataPoints": [
      {
        "timeUnixNano": "1699889318780000000",
        "count": "1000",
        "sum": 45231.0,
        "quantileValues": [
          {"quantile": 0.5, "value": 42.0},
          {"quantile": 0.95, "value": 98.0},
          {"quantile": 0.99, "value": 152.0}
        ]
      }
    ]
  }
}
```

#### Metric Data Point Attributes

All metric data points can have attributes for dimensionality:

```json
{
  "attributes": [
    {"key": "http.method", "value": {"stringValue": "POST"}},
    {"key": "http.route", "value": {"stringValue": "/api/users"}},
    {"key": "environment", "value": {"stringValue": "production"}}
  ]
}
```

These attributes allow grouping and filtering during analysis (e.g., "show request count by HTTP method").

---

## Error Files

Error files (`.errors.ndjson`) contain only telemetry entries with detected errors, enabling fast error analysis without scanning all telemetry data.

### Error File Pairing

Error files share timestamps with their corresponding normal files:

```
traces.20251116_143022_456.ndjson        ← All traces
traces.20251116_143022_456.errors.ndjson ← Only error traces

logs.20251116_143022_456.ndjson          ← All logs
logs.20251116_143022_456.errors.ndjson   ← Only error/fatal logs
```

### Detection Logic

**Traces** are written to error files when ANY span in the export contains:
- `status.code == 2` (STATUS_CODE_ERROR), OR
- Event with `name == "exception"`

**Logs** are written to error files when ANY log record contains:
- `severityNumber >= 17` (ERROR or FATAL), OR
- Attributes with keys: `exception.type`, `exception.message`, or `exception.stacktrace`

**Metrics**: No error files (metrics don't have error semantics)

### Performance Benefit

Error files provide **indexed access** to errors:
- Normal files: O(n) scan required to find errors
- Error files: O(1) - all entries are errors

**Example workflow:**
```bash
# Quick error check - fast, no full scan needed
ls *.errors.ndjson  # If exists, errors occurred

# Analyze only errors
cat traces.*.errors.ndjson | jq -r '.resourceSpans[].scopeSpans[].spans[] | select(.status.code == 2)'

# Count error occurrences
wc -l logs.20251116_143022_456.errors.ndjson
```

### Error File Cleanup

Error files are automatically deleted when using the `clear` command:

```bash
# Clears ALL .ndjson files (including .errors.ndjson)
opentelwatcher clear --output-dir ./telemetry-data
```

---

## Working with Timestamps

All OpenTelemetry timestamps use **nanoseconds since Unix epoch** (1970-01-01T00:00:00Z).

### Timestamp Fields

**Traces:**
- `startTimeUnixNano`: When operation started
- `endTimeUnixNano`: When operation completed
- Event `timeUnixNano`: When event occurred within span

**Logs:**
- `timeUnixNano`: When log event occurred
- `observedTimeUnixNano`: When log was collected/observed

**Metrics:**
- `startTimeUnixNano`: Beginning of measurement period (for Sum/Histogram)
- `timeUnixNano`: End of measurement period / sample time

### Converting Timestamps

**To seconds:**
```javascript
const timestampSeconds = parseInt(timeUnixNano) / 1e9;
```

**To milliseconds:**
```javascript
const timestampMs = parseInt(timeUnixNano) / 1e6;
```

**To Date object:**
```javascript
const date = new Date(parseInt(timeUnixNano) / 1e6);
console.log(date.toISOString()); // "2023-11-13T12:35:18.780Z"
```

**Python:**
```python
from datetime import datetime

timestamp_ns = int(data['timeUnixNano'])
timestamp_s = timestamp_ns / 1e9
dt = datetime.fromtimestamp(timestamp_s)
print(dt.isoformat())  # "2023-11-13T12:35:18.780000"
```

### Calculating Durations (Traces)

```javascript
const durationNs = parseInt(span.endTimeUnixNano) - parseInt(span.startTimeUnixNano);
const durationMs = durationNs / 1e6;
const durationSeconds = durationNs / 1e9;

console.log(`Span duration: ${durationMs.toFixed(2)} ms`);
```

### File Timestamp Extraction

Extract file creation time from filename:

```javascript
const filename = "traces.20251116_143022_456.ndjson";
const match = filename.match(/(\d{8})_(\d{6})_(\d{3})/);

if (match) {
  const [, date, time, ms] = match;
  // date = "20251116" → YYYY-MM-DD
  const year = date.substring(0, 4);
  const month = date.substring(4, 6);
  const day = date.substring(6, 8);

  // time = "143022" → HH:MM:SS
  const hour = time.substring(0, 2);
  const minute = time.substring(2, 4);
  const second = time.substring(4, 6);

  const isoString = `${year}-${month}-${day}T${hour}:${minute}:${second}.${ms}Z`;
  const fileCreatedAt = new Date(isoString);
}
```

### Filtering by Time Range

```python
import json
from datetime import datetime, timezone

# Target time range
start_time = datetime(2025, 11, 16, 14, 30, tzinfo=timezone.utc)
end_time = datetime(2025, 11, 16, 15, 0, tzinfo=timezone.utc)

start_ns = int(start_time.timestamp() * 1e9)
end_ns = int(end_time.timestamp() * 1e9)

# Filter spans
with open('traces.20251116_143022_456.ndjson', 'r') as f:
    for line in f:
        data = json.loads(line)
        for resource_span in data.get('resourceSpans', []):
            for scope_span in resource_span.get('scopeSpans', []):
                for span in scope_span.get('spans', []):
                    span_time = int(span['startTimeUnixNano'])
                    if start_ns <= span_time <= end_ns:
                        print(f"Span: {span['name']} at {span_time}")
```

---

## Testing Workflow Guidelines

When using OpenTelWatcher for testing, follow these best practices to ensure clean, performant, and analyzable test runs.

### Pre-Test Cleanup

**Always clear telemetry data before test runs** to:
1. Ensure only current test data is present
2. Improve performance (fewer files to scan)
3. Avoid confusion from previous test runs
4. Get accurate file counts and sizes

```bash
# Clear before running tests
opentelwatcher clear --output-dir ./telemetry-data --verbose

# Run your tests
npm test
# or
pytest
# or
dotnet test

# Analyze results
ls -lh ./telemetry-data/*.ndjson
```

### Test Isolation with Timestamps

Use file timestamps to identify which telemetry belongs to specific test runs:

**Option 1: Record start time**
```bash
# Record test start time
TEST_START=$(date -u +%s%N)  # Unix nanoseconds

# Run tests
npm test

# Filter telemetry after test start
# (parse NDJSON and compare timeUnixNano >= TEST_START)
```

**Option 2: Clear before each test**
```javascript
// In test setup
beforeEach(async () => {
  // Clear telemetry before each test
  await exec('opentelwatcher clear --silent');
});

afterEach(async () => {
  // Analyze telemetry from this test only
  const traces = await parseNdjson('./telemetry-data/traces.*.ndjson');
  expect(traces).toHaveNoErrors();
});
```

**Option 3: Use test-specific output directories**
```bash
# Test 1
opentelwatcher start --output-dir ./telemetry-data/test1 --daemon
run_test_1
opentelwatcher stop

# Test 2
opentelwatcher start --output-dir ./telemetry-data/test2 --daemon
run_test_2
opentelwatcher stop

# Analyze separately
ls ./telemetry-data/test1/
ls ./telemetry-data/test2/
```

### Performance Considerations

**File Indexing:**
- Normal `.ndjson` files are **NOT indexed** - scanning requires O(n) full file reads
- Error `.errors.ndjson` files provide **indexed access** to errors - O(1) error detection

**Performance Tips:**
1. **Use `clear` before tests** to minimize file count
2. **Check error files first** for fast error detection:
   ```bash
   if ls ./telemetry-data/*.errors.ndjson 1>/dev/null 2>&1; then
     echo "Errors detected!"
   fi
   ```
3. **Filter by timestamp** instead of reading all files
4. **Use streaming parsers** for large files (don't load entire file into memory)

### Test Assertion Patterns

**Check for errors:**
```javascript
const fs = require('fs');
const glob = require('glob');

function hasErrors(outputDir) {
  const errorFiles = glob.sync(`${outputDir}/*.errors.ndjson`);
  return errorFiles.length > 0;
}

// In test
expect(hasErrors('./telemetry-data')).toBe(false);
```

**Verify trace completion:**
```python
import json
import glob

def verify_trace_complete(output_dir, expected_span_count):
    trace_files = glob.glob(f"{output_dir}/traces.*.ndjson")
    total_spans = 0

    for file in trace_files:
        with open(file, 'r') as f:
            for line in f:
                data = json.loads(line)
                for rs in data.get('resourceSpans', []):
                    for ss in rs.get('scopeSpans', []):
                        total_spans += len(ss.get('spans', []))

    assert total_spans == expected_span_count, \
        f"Expected {expected_span_count} spans, got {total_spans}"
```

**Assert specific log messages:**
```python
def assert_log_message(output_dir, expected_message):
    log_files = glob.glob(f"{output_dir}/logs.*.ndjson")

    for file in log_files:
        with open(file, 'r') as f:
            for line in f:
                data = json.loads(line)
                for rl in data.get('resourceLogs', []):
                    for sl in rl.get('scopeLogs', []):
                        for log in sl.get('logRecords', []):
                            body = log.get('body', {}).get('stringValue', '')
                            if expected_message in body:
                                return True

    raise AssertionError(f"Log message not found: {expected_message}")
```

### End-to-End Test Example

```python
import subprocess
import time
import json
import glob
import os

def test_api_endpoint_telemetry():
    output_dir = "./telemetry-data"

    # 1. Clear previous telemetry
    subprocess.run(["opentelwatcher", "clear", "--output-dir", output_dir, "--silent"])

    # 2. Start watcher in daemon mode
    subprocess.run([
        "opentelwatcher", "start",
        "--daemon",
        "--port", "4318",
        "--output-dir", output_dir
    ])

    # Wait for startup
    time.sleep(2)

    try:
        # 3. Run application tests
        response = requests.get("http://localhost:8080/api/users")
        assert response.status_code == 200

        # Wait for telemetry export
        time.sleep(1)

        # 4. Verify telemetry
        # Check no errors occurred
        error_files = glob.glob(f"{output_dir}/*.errors.ndjson")
        assert len(error_files) == 0, "Unexpected errors in telemetry"

        # Verify trace created
        trace_files = glob.glob(f"{output_dir}/traces.*.ndjson")
        assert len(trace_files) > 0, "No trace files created"

        # Verify GET /api/users span exists
        found_span = False
        for file in trace_files:
            with open(file, 'r') as f:
                for line in f:
                    data = json.loads(line)
                    for rs in data.get('resourceSpans', []):
                        for ss in rs.get('scopeSpans', []):
                            for span in ss.get('spans', []):
                                if 'GET /api/users' in span.get('name', ''):
                                    found_span = True
                                    # Assert span successful
                                    assert span['status']['code'] in [0, 1]  # UNSET or OK

        assert found_span, "Expected 'GET /api/users' span not found"

    finally:
        # 5. Cleanup
        subprocess.run(["opentelwatcher", "stop"])
```

**.NET 10 xUnit test example:**

```csharp
using System.Diagnostics;
using System.Text.Json;
using Xunit;

namespace MyApp.Tests;

public class TelemetryTests : IAsyncLifetime
{
    private const string OutputDir = "./telemetry-data";
    private Process? _watcherProcess;

    public async Task InitializeAsync()
    {
        // 1. Clear previous telemetry
        await RunCommand("opentelwatcher", "clear --output-dir " + OutputDir + " --silent");

        // 2. Start watcher in daemon mode
        _watcherProcess = Process.Start(new ProcessStartInfo
        {
            FileName = "opentelwatcher",
            Arguments = $"start --daemon --port 4318 --output-dir {OutputDir}",
            UseShellExecute = false
        });

        // Wait for startup
        await Task.Delay(2000);
    }

    [Fact]
    public async Task ApiEndpoint_ShouldCreateSuccessfulTrace()
    {
        // 3. Run application request
        using var client = new HttpClient();
        var response = await client.GetAsync("http://localhost:8080/api/users");
        Assert.Equal(System.Net.HttpStatusCode.OK, response.StatusCode);

        // Wait for telemetry export
        await Task.Delay(1000);

        // 4. Verify telemetry
        // Check no errors occurred
        var errorFiles = Directory.GetFiles(OutputDir, "*.errors.ndjson");
        Assert.Empty(errorFiles); // No error files should exist

        // Verify trace created
        var traceFiles = Directory.GetFiles(OutputDir, "traces.*.ndjson");
        Assert.NotEmpty(traceFiles); // At least one trace file

        // Verify GET /api/users span exists
        bool foundSpan = false;
        foreach (var file in traceFiles)
        {
            foreach (var line in File.ReadLines(file))
            {
                using var doc = JsonDocument.Parse(line);
                var root = doc.RootElement;

                if (!root.TryGetProperty("resourceSpans", out var resourceSpans))
                    continue;

                foreach (var rs in resourceSpans.EnumerateArray())
                {
                    if (!rs.TryGetProperty("scopeSpans", out var scopeSpans))
                        continue;

                    foreach (var ss in scopeSpans.EnumerateArray())
                    {
                        if (!ss.TryGetProperty("spans", out var spans))
                            continue;

                        foreach (var span in spans.EnumerateArray())
                        {
                            var name = span.GetProperty("name").GetString();
                            if (name?.Contains("GET /api/users") == true)
                            {
                                foundSpan = true;

                                // Assert span successful (code 0=UNSET or 1=OK)
                                var statusCode = span.GetProperty("status")
                                    .GetProperty("code").GetInt32();
                                Assert.True(statusCode is 0 or 1,
                                    $"Expected success status, got {statusCode}");
                            }
                        }
                    }
                }
            }
        }

        Assert.True(foundSpan, "Expected 'GET /api/users' span not found");
    }

    public async Task DisposeAsync()
    {
        // 5. Cleanup
        await RunCommand("opentelwatcher", "stop");
        _watcherProcess?.Dispose();
    }

    private static async Task RunCommand(string command, string arguments)
    {
        var process = Process.Start(new ProcessStartInfo
        {
            FileName = command,
            Arguments = arguments,
            UseShellExecute = false,
            RedirectStandardOutput = true
        });

        if (process != null)
        {
            await process.WaitForExitAsync();
        }
    }
}
```

**Key .NET Testing Features:**
- Uses `IAsyncLifetime` for test setup/teardown
- `InitializeAsync()` starts OpenTelWatcher before test
- `DisposeAsync()` stops OpenTelWatcher after test
- Uses `System.Text.Json.JsonDocument` for NDJSON parsing
- Pattern matching with `is 0 or 1` for status codes
- Follows xUnit 3 async patterns

### CI/CD Integration

```yaml
# Example GitHub Actions workflow
name: Test with OpenTelemetry

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install OpenTelWatcher
        run: |
          wget https://github.com/user/opentelwatcher/releases/download/v1.0.0/opentelwatcher-linux-x64
          chmod +x opentelwatcher-linux-x64
          mv opentelwatcher-linux-x64 /usr/local/bin/opentelwatcher

      - name: Start OpenTelWatcher
        run: |
          opentelwatcher clear --silent
          opentelwatcher start --daemon --port 4318 --output-dir ./telemetry

      - name: Run tests
        run: npm test

      - name: Analyze telemetry
        run: |
          # Check for errors
          if ls ./telemetry/*.errors.ndjson 1>/dev/null 2>&1; then
            echo "::error::Errors found in telemetry"
            cat ./telemetry/*.errors.ndjson
            exit 1
          fi

          # Print statistics
          echo "Telemetry files created:"
          ls -lh ./telemetry/

      - name: Upload telemetry artifacts
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: telemetry-data
          path: ./telemetry/*.ndjson

      - name: Stop OpenTelWatcher
        if: always()
        run: opentelwatcher stop
```

---

## Common Analysis Patterns

### 1. Find All Errors in Traces

```bash
# Using error files (fastest)
cat traces.*.errors.ndjson | jq '.resourceSpans[].scopeSpans[].spans[] | select(.status.code == 2) | {name, traceId, error: .status.message}'

# Scanning all files (slower, but gets everything)
cat traces.*.ndjson | jq '.resourceSpans[].scopeSpans[].spans[] | select(.status.code == 2)'
```

**.NET 10 example - Find errors in trace files:**

Create `find_errors.cs`:
```csharp
#!/usr/bin/dotnet run
#:package System.Text.Json

using System.Text.Json;

// Check error files first (fastest)
var errorFiles = Directory.GetFiles(".", "traces.*.errors.ndjson");

if (errorFiles.Length > 0)
{
    Console.WriteLine("=== Errors found in trace files ===\n");

    foreach (var file in errorFiles)
    {
        foreach (var line in File.ReadLines(file))
        {
            using var doc = JsonDocument.Parse(line);
            var root = doc.RootElement;

            if (!root.TryGetProperty("resourceSpans", out var resourceSpans))
                continue;

            foreach (var rs in resourceSpans.EnumerateArray())
            {
                if (!rs.TryGetProperty("scopeSpans", out var scopeSpans))
                    continue;

                foreach (var ss in scopeSpans.EnumerateArray())
                {
                    if (!ss.TryGetProperty("spans", out var spans))
                        continue;

                    foreach (var span in spans.EnumerateArray())
                    {
                        if (!span.TryGetProperty("status", out var status))
                            continue;

                        if (status.TryGetProperty("code", out var code) && code.GetInt32() == 2)
                        {
                            var name = span.GetProperty("name").GetString();
                            var traceId = span.GetProperty("traceId").GetString();
                            var message = status.TryGetProperty("message", out var msg)
                                ? msg.GetString()
                                : "(no message)";

                            Console.WriteLine($"Error Span: {name}");
                            Console.WriteLine($"  TraceID: {traceId}");
                            Console.WriteLine($"  Message: {message}\n");
                        }
                    }
                }
            }
        }
    }
}
else
{
    Console.WriteLine("No error files found - no errors detected!");
}
```

Run:
```bash
dotnet run find_errors.cs
```

### 2. Count Spans by Kind

```bash
cat traces.*.ndjson | jq -r '.resourceSpans[].scopeSpans[].spans[].kind' | sort | uniq -c
# Output:
#   42 1  (INTERNAL)
#   18 2  (SERVER)
#   31 3  (CLIENT)
```

### 3. Calculate P95 Span Duration

```python
import json
import numpy as np

durations = []

with open('traces.20251116_143022_456.ndjson', 'r') as f:
    for line in f:
        data = json.loads(line)
        for rs in data.get('resourceSpans', []):
            for ss in rs.get('scopeSpans', []):
                for span in ss.get('spans', []):
                    start = int(span['startTimeUnixNano'])
                    end = int(span['endTimeUnixNano'])
                    duration_ms = (end - start) / 1e6
                    durations.append(duration_ms)

p50 = np.percentile(durations, 50)
p95 = np.percentile(durations, 95)
p99 = np.percentile(durations, 99)

print(f"P50: {p50:.2f}ms, P95: {p95:.2f}ms, P99: {p99:.2f}ms")
```

**.NET 10 example (using `dotnet run`):**

Create `analyze_durations.cs`:
```csharp
#!/usr/bin/dotnet run
#:package System.Text.Json

using System.Text.Json;

var durations = new List<double>();

// Read all trace files
foreach (var file in Directory.GetFiles(".", "traces.*.ndjson"))
{
    foreach (var line in File.ReadLines(file))
    {
        using var doc = JsonDocument.Parse(line);
        var root = doc.RootElement;

        if (!root.TryGetProperty("resourceSpans", out var resourceSpans))
            continue;

        foreach (var rs in resourceSpans.EnumerateArray())
        {
            if (!rs.TryGetProperty("scopeSpans", out var scopeSpans))
                continue;

            foreach (var ss in scopeSpans.EnumerateArray())
            {
                if (!ss.TryGetProperty("spans", out var spans))
                    continue;

                foreach (var span in spans.EnumerateArray())
                {
                    if (span.TryGetProperty("startTimeUnixNano", out var start) &&
                        span.TryGetProperty("endTimeUnixNano", out var end))
                    {
                        var startNs = long.Parse(start.GetString()!);
                        var endNs = long.Parse(end.GetString()!);
                        var durationMs = (endNs - startNs) / 1e6;
                        durations.Add(durationMs);
                    }
                }
            }
        }
    }
}

// Calculate percentiles
durations.Sort();
var p50 = Percentile(durations, 50);
var p95 = Percentile(durations, 95);
var p99 = Percentile(durations, 99);

Console.WriteLine($"P50: {p50:F2}ms, P95: {p95:F2}ms, P99: {p99:F2}ms");

double Percentile(List<double> sortedData, double percentile)
{
    if (sortedData.Count == 0) return 0;
    var index = (percentile / 100.0) * (sortedData.Count - 1);
    var lower = (int)Math.Floor(index);
    var upper = (int)Math.Ceiling(index);
    var weight = index - lower;
    return sortedData[lower] * (1 - weight) + sortedData[upper] * weight;
}
```

Run:
```bash
dotnet run analyze_durations.cs
```

### 4. Correlate Logs with Traces

```javascript
const fs = require('fs');
const readline = require('readline');

async function correlateLogsWithTrace(traceId) {
  const logs = [];
  const spans = [];

  // Read logs with matching traceId
  const logStream = readline.createInterface({
    input: fs.createReadStream('logs.20251116_143022_456.ndjson')
  });

  for await (const line of logStream) {
    const data = JSON.parse(line);
    for (const rl of data.resourceLogs || []) {
      for (const sl of rl.scopeLogs || []) {
        for (const log of sl.logRecords || []) {
          if (log.traceId === traceId) {
            logs.push(log);
          }
        }
      }
    }
  }

  // Read spans with matching traceId
  const traceStream = readline.createInterface({
    input: fs.createReadStream('traces.20251116_143022_456.ndjson')
  });

  for await (const line of traceStream) {
    const data = JSON.parse(line);
    for (const rs of data.resourceSpans || []) {
      for (const ss of rs.scopeSpans || []) {
        for (const span of ss.spans || []) {
          if (span.traceId === traceId) {
            spans.push(span);
          }
        }
      }
    }
  }

  return { logs, spans };
}

// Usage
correlateLogsWithTrace('5b8efff798038103d269b633813fc60c').then(result => {
  console.log(`Found ${result.spans.length} spans and ${result.logs.length} logs`);
});
```

### 5. Extract Exception Details from Error Logs

```bash
cat logs.*.errors.ndjson | jq -r '
  .resourceLogs[].scopeLogs[].logRecords[] |
  select(.severityNumber >= 17) |
  {
    timestamp: .timeUnixNano,
    severity: .severityText,
    message: .body.stringValue,
    exception_type: (.attributes[] | select(.key == "exception.type") | .value.stringValue),
    exception_message: (.attributes[] | select(.key == "exception.message") | .value.stringValue)
  }
'
```

### 6. Group Metrics by Attributes

```python
import json
from collections import defaultdict

metrics_by_method = defaultdict(list)

with open('metrics.20251116_143022_456.ndjson', 'r') as f:
    for line in f:
        data = json.loads(line)
        for rm in data.get('resourceMetrics', []):
            for sm in rm.get('scopeMetrics', []):
                for metric in sm.get('metrics', []):
                    if metric['name'] == 'http.server.duration':
                        for dp in metric.get('histogram', {}).get('dataPoints', []):
                            # Extract http.method attribute
                            method = None
                            for attr in dp.get('attributes', []):
                                if attr['key'] == 'http.method':
                                    method = attr['value']['stringValue']

                            if method:
                                metrics_by_method[method].append({
                                    'count': int(dp['count']),
                                    'sum': dp['sum']
                                })

# Calculate average duration per method
for method, datapoints in metrics_by_method.items():
    total_count = sum(dp['count'] for dp in datapoints)
    total_sum = sum(dp['sum'] for dp in datapoints)
    avg_duration = total_sum / total_count if total_count > 0 else 0
    print(f"{method}: {avg_duration:.2f}ms average ({total_count} requests)")
```

### 7. Reconstruct Trace Hierarchy

```javascript
function reconstructTrace(traceId, spans) {
  const spanMap = new Map();
  const rootSpans = [];

  // Index spans by spanId
  for (const span of spans) {
    if (span.traceId === traceId) {
      spanMap.set(span.spanId, { ...span, children: [] });
    }
  }

  // Build hierarchy
  for (const span of spanMap.values()) {
    if (span.parentSpanId && spanMap.has(span.parentSpanId)) {
      // Add as child to parent
      spanMap.get(span.parentSpanId).children.push(span);
    } else {
      // Root span (no parent)
      rootSpans.push(span);
    }
  }

  return rootSpans;
}

function printTraceTree(span, indent = 0) {
  const duration = (parseInt(span.endTimeUnixNano) - parseInt(span.startTimeUnixNano)) / 1e6;
  const status = span.status.code === 2 ? '❌' : '✅';
  console.log('  '.repeat(indent) + `${status} ${span.name} (${duration.toFixed(2)}ms)`);

  for (const child of span.children) {
    printTraceTree(child, indent + 1);
  }
}

// Usage
const traceHierarchy = reconstructTrace('5b8efff798038103d269b633813fc60c', allSpans);
traceHierarchy.forEach(root => printTraceTree(root));

// Output:
// ✅ GET /api/orders (145.32ms)
//   ✅ SELECT orders FROM database (42.15ms)
//   ❌ POST /payment-service (98.47ms)
//     ✅ Process payment (85.12ms)
```

---

## Additional Resources

- **OpenTelemetry OTLP Specification**: https://opentelemetry.io/docs/specs/otlp/
- **OpenTelemetry Semantic Conventions**: https://opentelemetry.io/docs/specs/semconv/
- **Trace Concepts**: https://opentelemetry.io/docs/concepts/signals/traces/
- **Log Data Model**: https://opentelemetry.io/docs/specs/otel/logs/data-model/
- **Metrics Data Model**: https://opentelemetry.io/docs/specs/otel/metrics/data-model/
- **NDJSON Format**: http://ndjson.org/

---

## Summary

**Key Takeaways for Claude Skills/Agents:**

1. **Parse line-by-line**: NDJSON files contain one JSON object per line
2. **Use error files**: Fast error detection via `.errors.ndjson` files (indexed)
3. **Understand hierarchies**:
   - Traces: ResourceSpans → ScopeSpans → Spans
   - Logs: ResourceLogs → ScopeLogs → LogRecords
   - Metrics: ResourceMetrics → ScopeMetrics → Metrics
4. **Correlate data**: Use `traceId` and `spanId` to link logs with traces
5. **Handle timestamps**: All times are nanoseconds since Unix epoch
6. **Test workflow**: Always `clear` before tests for clean analysis
7. **Performance**: Check error files first, filter by timestamp when possible
8. **Enum values**: Remember OTLP JSON uses integers (not strings) for enums

This comprehensive guide provides everything needed to interpret, analyze, and test with OpenTelWatcher's NDJSON telemetry files.
